<template>
  <div class="container mt-5">
    <!-- ì§„í–‰ ì‹œê°„ -->
    <div class="row justify-content-center">
      <div class="col-6 d-flex justify-content-center align-items-center">
        <div class="circle timer">{{ time }}ì´ˆ</div>
      </div>
    </div>

    <!-- ì§ˆë¬¸ê³¼ ë‹µë³€ -->
    <div class="question-section mt-4">
      <div v-if="currentQuestionIndex < questions.length">
        <div class="ai-response mb-3">
          <div class="d-flex">
            <div class="ai-icon">
              <span>ğŸ¤–</span>
            </div>
            <div class="ml-3">
              <div class="question-index">[ì§ˆë¬¸ {{ currentQuestionIndex + 1 }}]</div>
              <div class="question-text">{{ questions[currentQuestionIndex] }}</div>
            </div>
          </div>
        </div>

        <!-- ì‚¬ìš©ì ë‹µë³€ -->
        <div v-if="sttTexts.length" class="answer-section mt-2">
          <div class="d-flex align-items-center mb-2">
            <div class="user-icon">ğŸ‘¤</div>
            <div class="user-answer">[ë‚´ ë‹µë³€]</div>
          </div>
          <div v-for="(text, idx) in sttTexts" :key="idx" class="stt-text bubble mt-2">"{{ text }}"</div>
        </div>

        <!-- ë§ˆì´í¬ ë° ìŒì„± ì¸ì‹ -->
        <div class="d-flex justify-content-center mt-3">
          <button class="btn btn-primary" @click="startRecording" v-if="!isRecording && sttTexts.length === 0">ë‹µë³€í•˜ê¸°</button>
          <button class="btn btn-secondary ml-3" @click="listenToAnswer" v-if="sttTexts.length > 0">ë‚´ ë‹µë³€ ë“£ê¸°</button>
          <button class="btn btn-warning ml-3" @click="resetAnswer" v-if="sttTexts.length > 0">ë‹¤ì‹œ ë‹µë³€í•˜ê¸°</button>
        </div>
      </div>

      <!-- ë‹¤ìŒ ì§ˆë¬¸ ë²„íŠ¼ -->
      <div v-if="sttTexts.length && currentQuestionIndex < questions.length" class="d-flex justify-content-center mt-4">
        <button class="btn btn-success" @click="nextQuestion">ë‹¤ìŒ ì§ˆë¬¸</button>
      </div>
    </div>

    <!-- ìŒì„± ì¸ì‹ ë³¼ë¥¨ ì‹œê°í™” -->
    <div v-if="isRecording" class="volume-visual mt-4">
      <div class="volume-bar" :style="{ height: volumeHeight + 'px' }"></div>
    </div>
  </div>
</template>

<script setup>
import { ref, onMounted, nextTick } from 'vue';

const questions = ref([
  "MVC íŒ¨í„´ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
  "Vue.jsì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
  "JavaScriptì—ì„œ í´ë¡œì €ë€ ë¬´ì—‡ì¸ê°€ìš”?"
]); // ì—¬ëŸ¬ ì§ˆë¬¸ ë°°ì—´

// STT í…ìŠ¤íŠ¸ ì €ì¥
const sttTexts = ref([]);

// ì§„í–‰ ì‹œê°„
const time = ref(0);
let timerInterval = null;

// ìŒì„± ì¸ì‹ ìƒíƒœ
const isRecording = ref(false);
const volumeHeight = ref(0); // ë³¼ë¥¨ ë†’ì´
const currentQuestionIndex = ref(0); // í˜„ì¬ ì§ˆë¬¸ ì¸ë±ìŠ¤

// ìŒì„± ì¸ì‹ ê°ì²´
let recognition = null;

// Web Audio API ê´€ë ¨ ë³€ìˆ˜
let audioContext = null;
let analyser = null;
let mediaStreamSource = null;
let analyserDataArray = null;

onMounted(() => {
  startTimer();

  // ìŒì„± ì¸ì‹ ê°ì²´ ì´ˆê¸°í™”
  if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = true;
    recognition.lang = 'ko-KR';
    recognition.interimResults = true;

    recognition.onstart = () => {
      isRecording.value = true;
      setupAudioContext();
      nextTick(() => {
        startVolumeVisualization(); // DOM ì—…ë°ì´íŠ¸ê°€ ì™„ë£Œëœ í›„ í˜¸ì¶œ
      });
    };

    recognition.onend = () => {
      isRecording.value = false;
      stopVolumeVisualization();
    };

    recognition.onresult = (event) => {
      let interimTranscript = '';
      for (let i = event.resultIndex; i < event.results.length; i++) {
        if (event.results[i].isFinal) {
          sttTexts.value.push(event.results[i][0].transcript);
        } else {
          interimTranscript += event.results[i][0].transcript;
        }
      }
    };
  } else {
    console.log("ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
  }
});

// íƒ€ì´ë¨¸ ì‹œì‘ í•¨ìˆ˜
const startTimer = () => {
  time.value = 0;
  if (timerInterval) {
    clearInterval(timerInterval);
  }
  timerInterval = setInterval(() => {
    time.value += 1;
  }, 1000);
};

// ìŒì„± ì¸ì‹ ì‹œì‘
const startRecording = () => {
  if (recognition) {
    sttTexts.value = [];  // STT í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    recognition.start();
  }
};

// ë‚´ ë‹µë³€ ë“£ê¸°
const listenToAnswer = () => {
  const msg = new SpeechSynthesisUtterance(sttTexts.value.join(' '));
  window.speechSynthesis.speak(msg);
};

// ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
const nextQuestion = () => {
  if (currentQuestionIndex.value < questions.value.length - 1) {
    currentQuestionIndex.value++;
    sttTexts.value = []; // ë‹¤ìŒ ì§ˆë¬¸ì„ ìœ„í•´ ë‹µë³€ ì´ˆê¸°í™”
  } else {
    // ëª¨ë“  ì§ˆë¬¸ì´ ëë‚œ ê²½ìš°
    alert("ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
  }
};

// ë‹¤ì‹œ ë‹µë³€í•˜ê¸°
const resetAnswer = () => {
  sttTexts.value = []; // ì´ì „ ë‹µë³€ ì´ˆê¸°í™”
  if (!isRecording.value) { // ìŒì„± ì¸ì‹ì´ ì§„í–‰ ì¤‘ì´ì§€ ì•Šì„ ë•Œë§Œ ì‹œì‘
    startRecording(); // ìƒˆë¡œìš´ ë‹µë³€ ë…¹ìŒ ì‹œì‘
  }
};

// Web Audio API ì´ˆê¸°í™”
const setupAudioContext = () => {
  audioContext = new (window.AudioContext || window.webkitAudioContext)();
  analyser = audioContext.createAnalyser();
  analyser.fftSize = 256;  // ì£¼íŒŒìˆ˜ ë¶„ì„ì˜ í¬ê¸°
  analyserDataArray = new Uint8Array(analyser.frequencyBinCount);
  
  // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë°ì„ ë°›ê¸° ìœ„í•œ setup
  navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
    mediaStreamSource = audioContext.createMediaStreamSource(stream);
    mediaStreamSource.connect(analyser);
  }).catch((err) => {
    console.log("ë§ˆì´í¬ ê¶Œí•œ ì˜¤ë¥˜:", err);
  });
};

// ì‹¤ì‹œê°„ ë³¼ë¥¨ ì‹œê°í™”
const startVolumeVisualization = () => {
  const updateVolume = () => {
    analyser.getByteFrequencyData(analyserDataArray);  // í˜„ì¬ì˜ ë³¼ë¥¨ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    const average = analyserDataArray.reduce((a, b) => a + b, 0) / analyserDataArray.length;
    volumeHeight.value = average;  // í‰ê·  ë³¼ë¥¨ ê°’ì„ ë†’ì´ë¡œ ì„¤ì •

    if (isRecording.value) {
      requestAnimationFrame(updateVolume);  // ê³„ì†í•´ì„œ ì—…ë°ì´íŠ¸
    }
  };

  updateVolume();
};

// ë³¼ë¥¨ ì‹œê°í™” ì¢…ë£Œ
const stopVolumeVisualization = () => {
  volumeHeight.value = 0; // ë³¼ë¥¨ ë†’ì´ ì´ˆê¸°í™”
};
</script>

<style scoped>
.timer {
  font-size: 20px;
  font-weight: bold;
  padding: 5px;
  background-color: #28a745;
  color: white;
  border-radius: 20px;
  text-align: center;
  width: 150px;
  height: 40px;
}

.question-section {
  margin-top: 30px;
}

.volume-visual {
  display: flex;
  justify-content: center;
  align-items: flex-end;
  height: 100px; /* ë†’ì´ ì¡°ì • */
  margin-top: 20px;
}

.volume-bar {
  width: 10px; /* ë°”ì˜ ë„ˆë¹„ */
  background-color: #28a745;
  border-radius: 5px;
  transition: height 0.05s;
}
</style>
